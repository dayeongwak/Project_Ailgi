import 'dart:convert';
import 'dart:typed_data';
import 'dart:io';
import 'package:flutter/material.dart';
import 'package:flutter_chat_ui/flutter_chat_ui.dart';
import 'package:flutter_chat_types/flutter_chat_types.dart' as types;
import 'package:http/http.dart' as http;
import 'package:intl/intl.dart';
import 'package:flutter/services.dart';
import 'api_key.dart';
import 'chat_input.dart';
import 'package:flutter_tts/flutter_tts.dart';
import 'dart:math';

// Firebase íŒ¨í‚¤ì§€ ì„í¬íŠ¸
import 'package:firebase_auth/firebase_auth.dart';
import 'package:cloud_firestore/cloud_firestore.dart';
import 'package:firebase_storage/firebase_storage.dart';
import 'package:shared_preferences/shared_preferences.dart';

class ChatPage extends StatefulWidget {
  final DateTime selectedDay;
  final Function(String emotion) onEmotionAnalyzed;

  const ChatPage({
    super.key,
    required this.selectedDay,
    required this.onEmotionAnalyzed,
  });

  @override
  State<ChatPage> createState() => _ChatPageState();
}

class _ChatPageState extends State<ChatPage> {
  final _user = const types.User(id: 'user');
  final _bot = const types.User(id: 'bot');

  bool _isAnalyzing = false;
  String? _backgroundImagePath; // ë°°ê²½ ì´ë¯¸ì§€ë§Œ ë¡œì»¬ ìƒíƒœë¡œ ê´€ë¦¬ (í…Œë§ˆìƒ‰ì€ ë¶€ëª¨ì—ì„œ ë°›ìŒ)

  late FlutterTts _flutterTts;
  bool _isVoiceMode = false;
  bool _isAiSpeaking = false;
  final GlobalKey<ChatInputState> _chatInputKey = GlobalKey<ChatInputState>();

  // Firebase ì¸ìŠ¤í„´ìŠ¤
  final _firestore = FirebaseFirestore.instance;
  final _auth = FirebaseAuth.instance;
  final _storage = FirebaseStorage.instance;

  String get _dateKey => DateFormat('yyyy-MM-dd').format(widget.selectedDay);
  String? get _uid => _auth.currentUser?.uid;

  DocumentReference? get _diaryDocRef {
    if (_uid == null) return null;
    return _firestore.collection('users').doc(_uid).collection('diaries').doc(_dateKey);
  }

  CollectionReference? get _messagesColRef {
    return _diaryDocRef?.collection('messages');
  }

  final List<String> _initialGreetings = [
    "ì˜¤ëŠ˜ í•˜ë£¨ëŠ” ì–´ë• ë‚˜ìš”? ë‹¹ì‹ ì˜ ì´ì•¼ê¸°ë¥¼ ë“¤ë ¤ì£¼ì„¸ìš” ğŸ˜Š",
    "ì¢‹ì€ ë‚ ì”¨ì˜€ë‚˜ìš”? ì•„ë‹ˆë©´ ì¡°ê¸ˆ í˜ë“  í•˜ë£¨ì˜€ë‚˜ìš”? ì œê°€ ì˜†ì— ìˆì„ê²Œìš”. ğŸ«‚",
    "ê°€ì¥ ë¨¼ì € ê¸°ë¡í•˜ê³  ì‹¶ì€ ì˜¤ëŠ˜ì˜ íŠ¹ë³„í•œ ìˆœê°„ì´ ìˆë‚˜ìš”? âœï¸",
    "ë¬´ìŠ¨ ì¼ì´ ìˆì—ˆëŠ”ì§€ ê¶ê¸ˆí•´ìš”! í¸í•˜ê²Œ ë§í•´ì£¼ì„¸ìš”. ì €ëŠ” í•­ìƒ ë‹¹ì‹ ì˜ í¸ì´ì—ìš”.",
    "ì˜¤ëŠ˜ì˜ ë‹¹ì‹ ì˜ ê¸°ë¶„ì€ ì–´ë–¤ ìƒ‰ê¹”ì¸ê°€ìš”? ì´ì•¼ê¸°ë¥¼ ì‹œì‘í•´ë³¼ê¹Œìš”? ğŸŒˆ",
    "ì ê¹ ë“¤ëŸ¬ì¤˜ì„œ ê³ ë§ˆì›Œìš”. ì˜¤ëŠ˜ì€ ì–´ë–¤ ì¼ë“¤ì„ ê²ªì—ˆë‚˜ìš”? ì²œì²œíˆ ì´ì•¼ê¸°í•´ë´ìš”.",
  ];

  String _getRandomGreeting() {
    final random = Random();
    return _initialGreetings[random.nextInt(_initialGreetings.length)];
  }

  Future<void> _addInitialBotMessage() async {
    if (_messagesColRef != null) {
      final snapshot = await _messagesColRef!.limit(1).get();
      if (snapshot.docs.isEmpty) {
        final greeting = _getRandomGreeting();
        final botMsg = types.TextMessage(
          id: (DateTime.now().millisecondsSinceEpoch + 1).toString(),
          author: _bot,
          text: greeting,
          createdAt: DateTime.now().millisecondsSinceEpoch,
        );
        Future.microtask(() async {
          await _messagesColRef!.doc(botMsg.id).set(botMsg.toJson());
        });
      }
    }
  }

  @override
  void initState() {
    super.initState();
    _loadBackground(); // ë°°ê²½ ì´ë¯¸ì§€ë§Œ ë”°ë¡œ ë¡œë“œ
    _initTts();
  }

  // ë°°ê²½ ì´ë¯¸ì§€ ë¡œë“œ (í…Œë§ˆ ìƒ‰ìƒì€ main.dartì—ì„œ ë°›ìœ¼ë¯€ë¡œ ì œê±°)
  Future<void> _loadBackground() async {
    final prefs = await SharedPreferences.getInstance();
    final key = "${_uid ?? 'GUEST'}_app_background_image_url";
    if (mounted) {
      setState(() {
        _backgroundImagePath = prefs.getString(key);
      });
    }
  }

  Future<void> _initTts() async {
    _flutterTts = FlutterTts();
    await _flutterTts.setLanguage("ko-KR");
    await _flutterTts.setSpeechRate(0.5);

    _flutterTts.setStartHandler(() {
      if (mounted) setState(() => _isAiSpeaking = true);
    });

    _flutterTts.setCompletionHandler(() {
      if (mounted) setState(() => _isAiSpeaking = false);
      if (_isVoiceMode) {
        _chatInputKey.currentState?.startListening();
      }
    });

    _flutterTts.setCancelHandler(() {
      if (mounted) setState(() => _isAiSpeaking = false);
    });

    _flutterTts.setErrorHandler((msg) {
      if (mounted) setState(() => _isAiSpeaking = false);
      print("TTS Error: $msg");
    });
  }

  @override
  void dispose() {
    _flutterTts.stop();
    super.dispose();
  }

  Future<void> _speak(String text) async {
    if (text.trim().isEmpty) return;
    await _flutterTts.stop();
    await _flutterTts.speak(text);
  }

  Future<void> _toggleFavorite(bool currentIsFavorite) async {
    if (_diaryDocRef == null) return;
    HapticFeedback.lightImpact();
    await _diaryDocRef!.set(
      {'isFavorite': !currentIsFavorite},
      SetOptions(merge: true),
    );
    widget.onEmotionAnalyzed("");
  }

  Future<String> _getChatReply(String text) async {
    const systemPrompt = """
ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ í•˜ë£¨ë¥¼ ê¸°ë¡í•˜ê³  ê°ì •ì„ ê³µìœ í•˜ëŠ” ì¹œê·¼í•˜ê³  ë”°ëœ»í•œ AI ì¹œêµ¬ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ì˜ë„ëŠ” í•­ìƒ ìµœìš°ì„ ì…ë‹ˆë‹¤.
[ì—­í• ]:
1. ì‚¬ìš©ìì˜ ê°ì •ì„ ë¨¼ì € ì½ì–´ì£¼ê³  ê³µê°í•˜ë©° ëŒ€í™”í•˜ì„¸ìš”.
2. ë‹µë³€ì€ 2ë¬¸ì¥ ì´ë‚´ë¡œ ì‘ì„±í•˜ì„¸ìš”.
""";
    try {
      final res = await http.post(
        Uri.parse("https://api.openai.com/v1/chat/completions"),
        headers: { "Authorization": "Bearer $openAIApiKey", "Content-Type": "application/json", },
        body: jsonEncode({
          "model": "gpt-4o-mini",
          "messages": [
            {"role": "system", "content": systemPrompt},
            {"role": "user", "content": text}
          ],
        }),
      );
      final data = jsonDecode(utf8.decode(res.bodyBytes));
      return data["choices"]?[0]?["message"]?["content"] ?? "ì‘ë‹µì„ ì´í•´í•˜ì§€ ëª»í–ˆì–´ìš” ğŸ˜…";
    } catch (_) { return "ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì–´ìš” âš ï¸"; }
  }

  Future<String> _getChatReplyForImage(Uint8List imageBytes, String? mimeType) async {
    try {
      final String base64Image = base64Encode(imageBytes);
      final String dataUri = 'data:${mimeType ?? 'image/jpeg'};base64,$base64Image';
      const systemPrompt = "ë„ˆëŠ” ì‚¬ìš©ìì˜ ì¼ê¸° ì¹œêµ¬ì•¼. ì‚¬ìš©ìê°€ ë°©ê¸ˆ ì‚¬ì§„ì„ ë³´ëƒˆì–´. ì‚¬ì§„ì„ ë³´ê³  ëŠë‚€ ì ì´ë‚˜ ì§ˆë¬¸ì„ í¬í•¨í•˜ì—¬ ë‹¤ì •í•˜ê²Œ ì§§ê²Œ í•œë§ˆë”” í•´ì¤˜.";

      final res = await http.post(
        Uri.parse("https://api.openai.com/v1/chat/completions"),
        headers: { "Authorization": "Bearer $openAIApiKey", "Content-Type": "application/json", },
        body: jsonEncode({
          "model": "gpt-4o-mini",
          "messages": [
            {"role": "system", "content": systemPrompt},
            { "role": "user", "content": [
              { "type": "text", "text": "ì´ ì‚¬ì§„ì— ëŒ€í•´ ì¼ê¸° ì¹œêµ¬ì²˜ëŸ¼ ë‹µë³€í•´ì¤˜." },
              { "type": "image_url", "image_url": { "url": dataUri } }
            ] }
          ], "max_tokens": 100
        }),
      );
      if (res.statusCode == 200) {
        final data = jsonDecode(utf8.decode(res.bodyBytes));
        return data["choices"]?[0]?["message"]?["content"] ?? "ì‚¬ì§„ì„ ì˜ ë°›ì•˜ì–´ìš”! ğŸ–¼ï¸";
      } else { return "ì‚¬ì§„ì„ ë°›ì•˜ëŠ”ë°, ì§€ê¸ˆì€ ì˜ ì•ˆ ë³´ì´ë„¤ìš” ğŸ˜…"; }
    } catch (e) { return "ì‚¬ì§„ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì–´ìš” âš ï¸"; }
  }

  Future<String> _analyzeEmotion(String allText) async {
    const emotions = [
      "ê¸°ì¨","ìŠ¬í””","í™”ë‚¨","ì§œì¦","ë¬´ê¸°ë ¥","ë¶ˆì•ˆ","í‰ì˜¨","ì‚¬ë‘","ë†€ëŒ","ê°ì‚¬",
      "ì¢Œì ˆ","ìì‹ ê°","í›„íšŒ","í˜¼ë€","í”¼ê³¤","ë‹¹í™©","ì™¸ë¡œì›€","ë§Œì¡±","ìŠ¤íŠ¸ë ˆìŠ¤",
      "ê¸°ëŒ€","ë¿Œë“¯","ê¸´ì¥","ì¶©ê²©","í¬ë§","ê³µí—ˆ","ì§ˆíˆ¬","ì—´ì •","ì°¨ë¶„","ì¦ê±°ì›€",
      "ë¶€ë„ëŸ¬ì›€","ì‹¤ë§","ì„¤ë ˜","ì¡´ê²½","ë¶„ë…¸","ì˜ìš•","ì•ˆì •","í™˜í¬","ë™ê²½","ì´ˆì¡°",
      "í—ˆë¬´","ë¶„ì£¼","ì—´ë§","ì°¨ê°€ì›€","ê²½ì•…","ìš°ìš¸","ì¡´ì¤‘","ì—´ê´‘","ìš©ê¸°","ê°ë™",
      "ë¶ˆí¸","ë¬´ì„œì›€","ë°˜ê°€ì›€","í›„ë ¨","í‰í™”","í¬ê¸°","ê¸°ì ","ë‚­ë§Œ"
    ];
    final analysisPrompt = """
ë‹¹ì‹ ì€ ìµœê³  ìˆ˜ì¤€ì˜ ì‹¬ë¦¬í•™ìì´ì ê°ì • ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
ì•„ë˜ 'ëŒ€í™” ì „ì²´ ë‚´ìš©'ì„ ë¶„ì„í•˜ì—¬ ì‚¬ìš©ìì˜ 'ì „ë°˜ì ì¸ í•µì‹¬ ê°ì •'ì„ ë‹¨ í•˜ë‚˜ì˜ í‚¤ì›Œë“œë¡œ í™•ì •í•˜ì„¸ìš”.
[ë¶„ì„ ì§€ì¹¨]:
1. ê°ì • ëª©ë¡ [${emotions.join(', ')}] ì¤‘ì—ì„œ ì„ íƒí•´ì•¼ í•©ë‹ˆë‹¤.
2. ìµœì¢… ë‹µë³€ì€ ì˜¤ì§ ê°€ì¥ ì •í™•í•œ ê°ì • í‚¤ì›Œë“œ í•˜ë‚˜ì—¬ì•¼ í•©ë‹ˆë‹¤.
""";
    try {
      final res = await http.post(
        Uri.parse("https://api.openai.com/v1/chat/completions"),
        headers: { "Authorization": "Bearer $openAIApiKey", "Content-Type": "application/json", },
        body: jsonEncode({
          "model": "gpt-4o-mini",
          "messages": [
            { "role": "system", "content": analysisPrompt },
            {"role": "user", "content": "ëŒ€í™” ì „ì²´ ë‚´ìš©: $allText"}
          ],
        }),
      );
      final data = jsonDecode(utf8.decode(res.bodyBytes));
      String emotion = data["choices"]?[0]?["message"]?["content"]?.trim() ?? "í‰ì˜¨";
      if (!emotions.contains(emotion)) { emotion = "í‰ì˜¨"; }
      return emotion;
    } catch (e) { return "í‰ì˜¨"; }
  }

  Future<String> _generateEmotionComment(String emotion) async {
    try {
      final res = await http.post(
        Uri.parse("https://api.openai.com/v1/chat/completions"),
        headers: { "Authorization": "Bearer $openAIApiKey", "Content-Type": "application/json", },
        body: jsonEncode({
          "model": "gpt-4o-mini",
          "messages": [
            { "role": "system", "content": "ê°ì •ì— ì–´ìš¸ë¦¬ëŠ” í•œ ì¤„ ìœ„ë¡œÂ·ì¹­ì°¬ ì½”ë©˜íŠ¸ë¥¼ 25ì ì´ë‚´ë¡œ í•œêµ­ì–´ë¡œ ë§Œë“¤ì–´. ì´ëª¨ì§€ í•œë‘ ê°œ í¬í•¨." },
            {"role": "user", "content": emotion}
          ],
        }),
      );
      final data = jsonDecode(utf8.decode(res.bodyBytes));
      return data["choices"]?[0]?["message"]?["content"]?.trim() ?? "ì˜¤ëŠ˜ë„ ìˆ˜ê³ í–ˆì–´ìš” ğŸ’•";
    } catch (_) { return "ì˜¤ëŠ˜ë„ ìˆ˜ê³ í–ˆì–´ìš” ğŸ’•"; }
  }

  Future<String> _generateDiarySummary(String allText) async {
    const summaryPrompt = "ì‚¬ìš©ìì˜ ì¼ê¸° ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ 100ì ì´ë‚´ì˜ ì¹œê·¼í•œ ì¼ê¸° ìš”ì•½ ë¬¸ì¥(í”„ë¦¬ë·°) í•˜ë‚˜ë¥¼ ë§Œë“¤ì–´ì£¼ì„¸ìš”.";
    try {
      final res = await http.post(
        Uri.parse("https://api.openai.com/v1/chat/completions"),
        headers: { "Authorization": "Bearer $openAIApiKey", "Content-Type": "application/json", },
        body: jsonEncode({
          "model": "gpt-4o-mini",
          "messages": [
            { "role": "system", "content": summaryPrompt },
            {"role": "user", "content": "ëŒ€í™” ì „ì²´ ë‚´ìš©: $allText"}
          ],
        }),
      );
      final data = jsonDecode(utf8.decode(res.bodyBytes));
      return data["choices"]?[0]?["message"]?["content"]?.trim() ?? "ì˜¤ëŠ˜ë„ ì†Œì¤‘í•œ í•˜ë£¨ë¥¼ ê¸°ë¡í–ˆì–´ìš”!";
    } catch (e) { return "ì˜¤ëŠ˜ë„ ì†Œì¤‘í•œ í•˜ë£¨ë¥¼ ê¸°ë¡í–ˆì–´ìš”!"; }
  }

  String _getEmojiForEmotion(String emotion) {
    const map = {
      "ê¸°ì¨": "ğŸ˜", "ìŠ¬í””": "ğŸ˜¢", "í™”ë‚¨": "ğŸ˜¡", "ì§œì¦": "ğŸ˜’", "ë¬´ê¸°ë ¥": "ğŸ¥±",
      "ë¶ˆì•ˆ": "ğŸ˜¨", "í‰ì˜¨": "ğŸ˜Œ", "ì‚¬ë‘": "ğŸ˜", "ë†€ëŒ": "ğŸ˜²", "ê°ì‚¬": "ğŸ¤—",
      "ì¢Œì ˆ": "ğŸ˜¤", "ìì‹ ê°": "ğŸ˜", "í›„íšŒ": "ğŸ˜”", "í˜¼ë€": "ğŸ¤”", "í”¼ê³¤": "ğŸ˜´",
      "ë‹¹í™©": "ğŸ˜•", "ì™¸ë¡œì›€": "ğŸ˜­", "ë§Œì¡±": "ğŸ˜‡", "ìŠ¤íŠ¸ë ˆìŠ¤": "ğŸ¤¯", "ê¸°ëŒ€": "ğŸ¤",
      "ë¿Œë“¯": "ğŸ‘", "ê¸´ì¥": "ğŸ˜¬", "ì¶©ê²©": "ğŸ˜±", "í¬ë§": "ğŸŒˆ", "ê³µí—ˆ": "ğŸ¥€",
      "ì§ˆíˆ¬": "ğŸ§", "ì—´ì •": "ğŸ”¥", "ì°¨ë¶„": "ğŸ§˜", "ì¦ê±°ì›€": "ğŸ‰", "ë¶€ë„ëŸ¬ì›€": "ğŸ˜³",
      "ì‹¤ë§": "ğŸ™", "ì„¤ë ˜": "ğŸ’“", "ì¡´ê²½": "ğŸ™", "ë¶„ë…¸": "ğŸ’¢", "ì˜ìš•": "ğŸ’ª",
      "ì•ˆì •": "ğŸ›¡ï¸", "í™˜í¬": "ğŸ¥³", "ë™ê²½": "ğŸŒ ", "ì´ˆì¡°": "ğŸ˜°", "í—ˆë¬´": "ğŸ˜¶",
      "ë¶„ì£¼": "ğŸƒ", "ì—´ë§": "âš¡", "ì°¨ê°€ì›€": "ğŸ¥¶", "ê²½ì•…": "ğŸ¤¯", "ìš°ìš¸": "ğŸ˜",
      "ì¡´ì¤‘": "ğŸ¤", "ì—´ê´‘": "âš¡", "ìš©ê¸°": "ğŸ¦¸", "ê°ë™": "ğŸ¥¹", "ë¶ˆí¸": "ğŸ˜£",
      "ë¬´ì„œì›€": "ğŸ‘»", "ë°˜ê°€ì›€": "ğŸ˜Š", "í›„ë ¨": "ğŸ˜®â€ğŸ’¨", "í‰í™”": "ğŸ•Šï¸", "í¬ê¸°": "ğŸ˜",
      "ê¸°ì ": "âœ¨", "ë‚­ë§Œ": "ğŸŒ¹"
    };
    return map[emotion] ?? "âœ¨";
  }

  Future<void> _endDiary(List<types.Message> currentMessages) async {
    final scaffoldMessenger = ScaffoldMessenger.of(context);
    if (_diaryDocRef == null || _messagesColRef == null) return;
    if (currentMessages.isEmpty) {
      scaffoldMessenger.showSnackBar( const SnackBar(content: Text("ë¨¼ì € ëŒ€í™”ë¥¼ ë‚˜ëˆ ë³´ì„¸ìš” ğŸ’¬")), );
      return;
    }

    setState(() => _isAnalyzing = true);

    try {
      final allText = currentMessages
          .whereType<types.TextMessage>()
          .where((m) => !m.text.startsWith("ì˜¤ëŠ˜ì˜ ê°ì •ì€"))
          .map((m) => "${m.author.id == 'user' ? 'ì‚¬ìš©ì: ' : 'AI: '}${m.text}").join("\n");

      final emotion = allText.trim().isEmpty ? "í‰ì˜¨" : await _analyzeEmotion(allText);
      final comment = await _generateEmotionComment(emotion);
      final summary = await _generateDiarySummary(allText);

      await _diaryDocRef!.set(
          {
            'emotion': emotion,
            'summary': summary,
            'allText': allText,
            'timestamp': widget.selectedDay,
          },
          SetOptions(merge: true)
      );

      final String emotionEmoji = _getEmojiForEmotion(emotion);
      final emotionMsg = types.TextMessage(
        id: DateTime.now().millisecondsSinceEpoch.toString(),
        author: _bot,
        text: "ì˜¤ëŠ˜ì˜ ê°ì •ì€ '$emotion' $emotionEmoji ì´ì—ìš”.\n$comment",
        createdAt: DateTime.now().millisecondsSinceEpoch,
      );
      await _messagesColRef!.add(emotionMsg.toJson());

      setState(() => _isAnalyzing = false);
      widget.onEmotionAnalyzed(emotion);
      if (_isVoiceMode) { await _speak(emotionMsg.text); }
      scaffoldMessenger.showSnackBar( const SnackBar(content: Text("ì˜¤ëŠ˜ ì¼ê¸°ë¥¼ ë§ˆë¬´ë¦¬í–ˆì–´ìš” ğŸ“”")), );

    } catch (e) {
      setState(() => _isAnalyzing = false);
      scaffoldMessenger.showSnackBar(
        SnackBar(content: Text("ì¼ê¸° ì €ì¥ ì‹¤íŒ¨: $e"), backgroundColor: Colors.red),
      );
    }
  }

  void _confirmDeleteChat() async {
    final scaffoldMessenger = ScaffoldMessenger.of(context);
    final navigator = Navigator.of(context);
    if (_diaryDocRef == null || _messagesColRef == null) return;
    if (_isVoiceMode) await _flutterTts.stop();
    final confirm = await showDialog<bool>(
      context: context,
      builder: (ctx) => AlertDialog(
        title: const Text("ì±„íŒ… ì‚­ì œ"),
        content: const Text("ì´ ë‚ ì§œì˜ ëª¨ë“  ì±„íŒ…, ê°ì • ìŠ¤í‹°ì»¤, ì¦ê²¨ì°¾ê¸°ë¥¼ ì‚­ì œí•˜ì‹œê² ì–´ìš”?"),
        actions: [
          TextButton( onPressed: () => Navigator.pop(ctx, false), child: const Text("ì·¨ì†Œ"), ),
          TextButton( onPressed: () => Navigator.pop(ctx, true), child: const Text("ì‚­ì œ", style: TextStyle(color: Colors.red)), ),
        ],
      ),
    );
    if (confirm == true) {
      try {
        final messagesSnapshot = await _messagesColRef!.get();
        final batch = _firestore.batch();
        for (final doc in messagesSnapshot.docs) { batch.delete(doc.reference); }
        batch.delete(_diaryDocRef!);
        await batch.commit();
        widget.onEmotionAnalyzed("");
        scaffoldMessenger.showSnackBar( const SnackBar(content: Text("ì¼ê¸°ì™€ ì¦ê²¨ì°¾ê¸°ê°€ ì‚­ì œë˜ì—ˆì–´ìš” ğŸ§¹")), );
        navigator.pop(true);
      } catch (e) { scaffoldMessenger.showSnackBar( SnackBar(content: Text("ì‚­ì œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: $e")), ); }
    }
  }

  void _handleSendPressed(String text) async {
    if (_messagesColRef == null) return;
    final userMsg = types.TextMessage(
      id: DateTime.now().millisecondsSinceEpoch.toString(),
      author: _user, text: text, createdAt: DateTime.now().millisecondsSinceEpoch,
    );
    await _messagesColRef!.add(userMsg.toJson());
    final lower = text.trim();
    const endKeywords = [ "ë","ê·¸ë§Œ","ì´ì œ ê·¸ë§Œ","ì˜¤ëŠ˜ì€ ì—¬ê¸°ê¹Œì§€","ì˜ë˜","ìê³  ì‹¶ì–´", "ëë‚´ì","ëë‚¼ê²Œ","ëë‚¼ë˜","ê·¸ë§Œ ì“¸ë˜","ê·¸ë§Œ ì“¸ê±°ì•¼","ì¼ê¸° ë", "ìˆ˜ê³ í–ˆì–´","ì˜¤ëŠ˜ ê¸°ë¡ ë","ì´ì œ ì‰¬ì","ì´ì œ ìì•¼ê² ë‹¤" ];
    final isEndSignal = endKeywords.contains(lower);

    final reply = await _getChatReply(text);

    final botMsg = types.TextMessage(
      id: (DateTime.now().millisecondsSinceEpoch + 1).toString(),
      author: _bot, text: reply, createdAt: DateTime.now().millisecondsSinceEpoch,
    );
    await _messagesColRef!.doc(botMsg.id).set(botMsg.toJson());
    if (_isVoiceMode && !isEndSignal) { await _speak(reply); }
    if (isEndSignal) {
      final currentMessagesSnapshot = await _messagesColRef!.orderBy('createdAt', descending: true).get();
      final currentMessages = currentMessagesSnapshot.docs.map((doc) => types.Message.fromJson(doc.data() as Map<String, dynamic>)).toList();
      await _endDiary(currentMessages);
    }
  }

  Future<void> _handleSendImage(String path) async {
    final scaffoldMessenger = ScaffoldMessenger.of(context);
    if (_messagesColRef == null || _uid == null) return;

    if (_isVoiceMode) await _flutterTts.stop();

    final file = File(path);
    final String tempMessageId = DateTime.now().millisecondsSinceEpoch.toString();

    try {
      final bytes = await file.readAsBytes();
      final image = await decodeImageFromList(bytes);

      final String xfileName = file.path.split('/').last;
      final double imgHeight = image.height.toDouble();
      final double imgWidth = image.width.toDouble();
      final int imgSize = bytes.length;
      final String? mimeType = "image/jpeg";

      final tempMessage = types.ImageMessage(
        author: _user,
        createdAt: DateTime.now().millisecondsSinceEpoch,
        height: imgHeight,
        id: tempMessageId,
        name: xfileName,
        size: imgSize,
        uri: path,
        width: imgWidth,
        status: types.Status.sending,
      );
      await _messagesColRef!.doc(tempMessageId).set(tempMessage.toJson());

      final ref = _storage.ref('users/$_uid/images/${_dateKey}_$tempMessageId.jpg');
      final uploadTask = ref.putData(bytes, SettableMetadata(contentType: mimeType));
      final snapshot = await uploadTask;
      final downloadUrl = await snapshot.ref.getDownloadURL();

      final finalMessage = tempMessage.copyWith(
        uri: downloadUrl,
        status: types.Status.sent,
      );
      await _messagesColRef!.doc(tempMessageId).update(finalMessage.toJson());

      final reply = await _getChatReplyForImage(bytes, mimeType);
      final botMsg = types.TextMessage(
        id: (DateTime.now().millisecondsSinceEpoch + 1).toString(),
        author: _bot,
        text: reply,
        createdAt: DateTime.now().millisecondsSinceEpoch,
      );
      await _messagesColRef!.doc(botMsg.id).set(botMsg.toJson());

      if (_isVoiceMode) {
        await _speak(reply);
      }

    } catch (e) {
      await _messagesColRef!.doc(tempMessageId).update({'status': 'error'});
      scaffoldMessenger.showSnackBar(
        SnackBar(content: Text("ì´ë¯¸ì§€ ì „ì†¡ ì‹¤íŒ¨: $e")),
      );
    }
  }

  // ìƒ‰ìƒì„ ë” ì–´ë‘¡ê²Œ ë§Œë“œëŠ” í•¨ìˆ˜ (í…Œë§ˆ ì ìš©ì„ ìœ„í•´ í•„ìš”)
  Color _darkerColor(Color color, [double factor = 0.85]) {
    final HSLColor hsl = HSLColor.fromColor(color);
    final HSLColor darkerHsl = hsl.withLightness((hsl.lightness * factor).clamp(0.0, 1.0));
    return darkerHsl.toColor();
  }

  void _toggleVoiceMode() {
    setState(() => _isVoiceMode = !_isVoiceMode);
    if (_isVoiceMode) {
      HapticFeedback.lightImpact();
      if (!_isAiSpeaking) { _chatInputKey.currentState?.startListening(); }
    } else { _flutterTts.stop(); }
  }

  @override
  Widget build(BuildContext context) {
    if (_uid == null || _diaryDocRef == null || _messagesColRef == null) {
      return Scaffold(
        appBar: AppBar(backgroundColor: Colors.white),
        body: const Center( child: Text("ë¡œê·¸ì¸ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤."), ),
      );
    }

    // âœ… [í•µì‹¬ ìˆ˜ì •] main.dartì—ì„œ ì„¤ì •í•œ ì „ì²´ í…Œë§ˆ ìƒ‰ìƒì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
    final themeColor = Theme.of(context).primaryColor;
    final isDark = themeColor.computeLuminance() < 0.5;
    final textColor = isDark ? Colors.white : Colors.black;

    return Scaffold(
      appBar: AppBar(
        backgroundColor: themeColor,
        title: Text(
          DateFormat('yyyy/MM/dd').format(widget.selectedDay),
          style: TextStyle(color: textColor),
        ),
        iconTheme: IconThemeData(color: textColor),
        actions: [
          StreamBuilder<DocumentSnapshot>(
            stream: _diaryDocRef!.snapshots(),
            builder: (context, snapshot) {
              bool isFavorite = false;
              if (snapshot.hasData && snapshot.data!.exists) {
                final data = snapshot.data!.data() as Map<String, dynamic>;
                isFavorite = data['isFavorite'] ?? false;
              }
              return IconButton(
                tooltip: isFavorite ? 'ì¦ê²¨ì°¾ê¸° í•´ì œ' : 'ì¦ê²¨ì°¾ê¸°',
                icon: Icon(
                  isFavorite ? Icons.star : Icons.star_border,
                  color: isFavorite ? Colors.amber : textColor,
                ),
                onPressed: () => _toggleFavorite(isFavorite),
              );
            },
          ),
          IconButton(
            tooltip: 'ì±„íŒ… ì‚­ì œ',
            icon: Icon(Icons.delete, color: textColor),
            onPressed: _confirmDeleteChat,
          ),
        ],
      ),
      body: Stack(
        fit: StackFit.expand,
        children: [
          if (_backgroundImagePath != null)
            Image.network(_backgroundImagePath!, fit: BoxFit.cover)
          else
            Container(color: themeColor),
          if (_backgroundImagePath != null)
            Container(color: Colors.black.withOpacity(0.3)),

          StreamBuilder<QuerySnapshot>(
            stream: _messagesColRef!.orderBy('createdAt', descending: true).snapshots(),
            builder: (context, snapshot) {
              if (snapshot.connectionState == ConnectionState.waiting) {
                return Center( child: CircularProgressIndicator(color: textColor), );
              }

              final messages = snapshot.data?.docs.map((doc) {
                final data = doc.data() as Map<String, dynamic>;
                if (data['createdAt'] is Timestamp) {
                  data['createdAt'] = (data['createdAt'] as Timestamp).millisecondsSinceEpoch;
                }
                return types.Message.fromJson(data);
              }).toList() ?? [];

              if (messages.isEmpty && snapshot.connectionState == ConnectionState.active) {
                _addInitialBotMessage();
              }

              return Chat(
                messages: messages,
                onSendPressed: (types.PartialText message) { },
                user: _user,
                showUserAvatars: true,
                avatarBuilder: (authorId) => const SizedBox.shrink(),
                showUserNames: false,
                theme: DefaultChatTheme(
                  backgroundColor: Colors.transparent,
                  primaryColor: _darkerColor(themeColor, 0.9),
                  secondaryColor: Colors.white.withOpacity(0.9),
                  receivedMessageBodyTextStyle: const TextStyle( color: Colors.black87, fontWeight: FontWeight.w500, ),
                  sentMessageBodyTextStyle: TextStyle( color: textColor, fontWeight: FontWeight.w500, ),
                ),
                customBottomWidget: ChatInput(
                  key: _chatInputKey,
                  onSendMessage: _handleSendPressed,
                  onSendImage: _handleSendImage,
                  themeColor: _darkerColor(themeColor),
                  textColor: textColor,
                ),
              );
            },
          ),
          Positioned(
            top: 16, right: 16,
            child: FloatingActionButton.extended(
              backgroundColor: _darkerColor(themeColor),
              foregroundColor: textColor,
              elevation: 4,
              shape: RoundedRectangleBorder( borderRadius: BorderRadius.circular(12), side: BorderSide( color: textColor == Colors.black ? Colors.black.withAlpha(64) : Colors.white.withAlpha(128), width: 1.2, ), ),
              label: AnimatedSwitcher(
                duration: const Duration(milliseconds: 300),
                child: _isAnalyzing
                    ? const Row( key: ValueKey('loading'), children: [ SizedBox( height: 20, width: 20, child: CircularProgressIndicator(strokeWidth: 2), ), SizedBox(width: 10), Text("ë¶„ì„ ì¤‘..."), ], )
                    : Row( key: const ValueKey('default'), children: [ const Icon(Icons.done_all), const SizedBox(width: 8), Text( "ì¼ê¸° ë§ˆë¬´ë¦¬", style: TextStyle( color: textColor, fontWeight: FontWeight.bold, fontSize: 14.5, ), ), ], ),
              ),
              onPressed: _isAnalyzing ? null : () async {
                final snapshot = await _messagesColRef!.orderBy('createdAt', descending: true).get();
                final currentMessages = snapshot.docs.map((doc) {
                  final data = doc.data() as Map<String, dynamic>;
                  if (data['createdAt'] is Timestamp) { data['createdAt'] = (data['createdAt'] as Timestamp).millisecondsSinceEpoch; }
                  return types.Message.fromJson(data);
                }).toList();
                await _endDiary(currentMessages);
              },
            ),
          ),
          Positioned(
            top: 80, right: 16,
            child: FloatingActionButton(
              mini: true,
              backgroundColor: _darkerColor(themeColor),
              foregroundColor: _isVoiceMode ? Colors.blueAccent : textColor,
              elevation: 4,
              shape: RoundedRectangleBorder( borderRadius: BorderRadius.circular(12), side: BorderSide( color: textColor == Colors.black ? Colors.black.withAlpha(64) : Colors.white.withAlpha(128), width: 1.2, ), ),
              onPressed: _toggleVoiceMode,
              tooltip: 'ìŒì„± ëŒ€í™” ëª¨ë“œ',
              child: Icon( _isVoiceMode ? Icons.volume_up : Icons.volume_off_outlined, ),
            ),
          ),
        ],
      ),
    );
  }
}